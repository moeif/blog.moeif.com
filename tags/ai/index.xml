<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Meowsay</title>
    <link>https://blog.meowsay.com/tags/ai/</link>
    <description>Recent content in AI on Meowsay</description>
    <image>
      <title>Meowsay</title>
      <url>https://blog.meowsay.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://blog.meowsay.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 16 Dec 2023 11:59:15 +0800</lastBuildDate><atom:link href="https://blog.meowsay.com/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>用AI做东西 - (03) 揭秘GPT模型中的标记和预测逻辑</title>
      <link>https://blog.meowsay.com/posts/devapp-with-ai-03-token-and-prediction/</link>
      <pubDate>Sat, 16 Dec 2023 11:59:15 +0800</pubDate>
      
      <guid>https://blog.meowsay.com/posts/devapp-with-ai-03-token-and-prediction/</guid>
      <description>GPT 系列的 LLM 接收提示作为输入，然后生成文本。这个过程被称为文本补全。例如，提示可能是 &amp;ldquo;The weather is nice today, so I decided to&amp;rdquo;，而模型的输出可能是 &amp;ldquo;go for a walk&amp;rdquo;。您可能想知道 LLM 模型是如何根据输入提示构建输出文本的。正如你将看到的，这主要是一个概率问题。
在向 LLM 发送提示（prompt）时，LLM 会首先将输入内容分割成更小的片段（称为 &amp;ldquo;标记&amp;rdquo;）也就是 token。这些标记（token）代表单个单词、单词的一部分或空格和标点符号。例如，前面的提示可以这样分解： &amp;ldquo;the&amp;rdquo;、&amp;ldquo;wea&amp;rdquo;、&amp;ldquo;ther&amp;rdquo;、&amp;ldquo;is&amp;rdquo;、&amp;ldquo;nice&amp;rdquo;、&amp;ldquo;today&amp;rdquo;、&amp;quot;,&amp;quot;、&amp;ldquo;so&amp;rdquo;、&amp;ldquo;I&amp;rdquo;、&amp;ldquo;de&amp;rdquo;、&amp;ldquo;ci&amp;rdquo;、&amp;ldquo;ded&amp;rdquo;、&amp;ldquo;to&amp;rdquo;。每个语言模型 都有自己的标记符。在撰写本文时，GPT-4 标记符号生成器还不可用，但您可以测试 GPT-3 标记符号生成器。
从单词长度的角度来理解词块的经验法则是，100 个词块约等于英文文本中的 75 个单词。
借助前面介绍的注意力原则和 Transformer 架构，LLM 可以处理这些标记，并解释它们之间的关系和提示的整体含义。Transformer 架构允许模型有效识别文本中的关键信息和上下文。
要创建一个新句子，LLM 会根据提示上下文预测最有可能出现的词组。OpenAI 制作了两个版本的 GPT-4，上下文窗口分别为 8,192 个和 32,768 个。以前的递归模型很难处理长输入序列，与之不同的是，带有注意力机制的 Transformer 架构允许现代 LLM 将上下文作为一个整体来考虑。根据上下文，模型会为每个潜在的后续标记分配一个概率分数。然后，概率最高的标记被选为序列中的下一个标记。在我们的例子中，在 &amp;ldquo;The weather is nice today, so I decided to &amp;ldquo;之后，下一个最佳标记可能是 &amp;ldquo;go&amp;rdquo;。
然后重复这一过程，但现在的语境变成了 &amp;ldquo;The weather is nice today, so I decided to go&amp;rdquo;，这时先前预测的标记 &amp;ldquo;go&amp;quot;被添加到原始提示中。模型可能预测的第二个标记是 &amp;ldquo;for&amp;rdquo;。这个过程不断重复，直到形成一个完整的句子： &amp;ldquo;go for a walk&amp;rdquo;。这个过程依靠的是 LLM 从海量文本数据中学习下一个最有可能出现的单词的能力。</description>
    </item>
    
    <item>
      <title>用AI做东西 - (02) 理解Transformer在LLM中的作用</title>
      <link>https://blog.meowsay.com/posts/devapp-with-ai-02-transformer-llm/</link>
      <pubDate>Fri, 15 Dec 2023 11:59:15 +0800</pubDate>
      
      <guid>https://blog.meowsay.com/posts/devapp-with-ai-02-transformer-llm/</guid>
      <description>Transformer 架构彻底改变了 NLP，这主要是因为 Transformer 有效地解决了以往 NLP 模型（如 RNN）的一个关键局限性：它们在处理长文本序列和在这些长度的文本序列中保持上下文时所面临的困难。换句话说，RNN 往往会遗忘较长文本序列中的上下文（即臭名昭著的 &amp;ldquo;灾难性遗忘&amp;rdquo;），而 Transformer 则能有效处理和编码上下文。
这场革命的核心支柱是注意力机制，这是一个简单而强大的理念。该模型不是将文本序列中的所有单词视为同等重要，而是&amp;quot;关注&amp;quot;其任务每一步中最相关的术语。交叉注意和自我注意是基于这种注意机制的两个架构模块，它们经常出现在 LLM 中。Transformer 架构广泛使用了这些交叉注意和自我注意模块。
交叉关注有助于模型确定输入文本不同部分的相关性，从而准确预测输出文本中的下一个单词。它就像一盏聚光灯，照亮输入文本中的单词或短语。突出显示预测下一个单词所需的相关信息，而忽略不那么重要的细节。
为了说明这一点，让我们以一个简单的句子翻译任务为例。假设我们有一个输入的英语句子，&amp;ldquo;Alice enjoyed the sunny weather in Brussels&amp;rdquo;，它被翻译成法语，&amp;ldquo;Alice a profité du temps ensoleillé à Bruxelles&amp;rdquo;。在这个例子中，重点生成法语单词 ensoleillé，它的意思是阳光明媚。对于这个预测，交叉注意会更多地考虑英语单词 sunny 和 weather，因为它们都与 ensoleillé 的意思相关。通过关注这两个词，交叉注意可以帮助模型为这部分句子生成准确的翻译。
自我关注指的是模型关注输入文本不同部分的能力。在 NLP 的语境中，模型可以评估句子中每个单词与其他单词的重要性。这可以让模型更好地理解词语之间的关系，并帮助模型从输入文本中的多个词语中建立新的概念。
举一个更具体的例子： &amp;ldquo;Alice received praise from her colleagues.&amp;quot;。假设模型正试图理解句子中 &amp;ldquo;her&amp;rdquo; 一词的含义。自我注意机制会给句子中的单词分配不同的权重，在这种情况下突出与 her 相关的单词。在这个例子中，自我注意力会给 Alice 和 colleagues 这两个词更多的权重。自我关注可以帮助模型从这些词语中建立新的概念。在本例中，可能出现的概念之一是 &amp;ldquo;Alice’s colleagues&amp;rdquo;。
与递归架构不同，Transformer 还具有易于并行化的优势。这意味着 Transformer 架构可以同时而不是按顺序处理输入文本的多个部分。这可以加快计算和训练速度，因为模型的不同部分可以并行工作，而无需等待前面的步骤完成，这与需要顺序处理的递归架构不同。Transformer 模型的并行处理能力与图形处理器（GPU）的架构完美契合，后者旨在同时处理多项计算。因此，GPU 凭借其高度并行性和计算能力，成为训练和运行这些 Transformer 模型的理想选择。这一进步使数据科学家能够在更大的数据集上训练模型，为开发 LLM 铺平了道路。
谷歌的 Vaswani 等人在 2017 年发表的论文《Attention Is All You Need》中介绍了 Transformer 架构，该架构最初是为机器翻译等序列到序列任务而开发的。标准 Transformer 由两个主要部分组成：编码器和解码器，这两个部分都在很大程度上依赖于注意力机制。编码器的任务是处理输入文本，识别有价值的特征，并生成有意义的文本表示，即嵌入。然后，解码器利用这种嵌入产生输出，如翻译或摘要。该输出可有效解释编码信息。</description>
    </item>
    
    <item>
      <title>用AI做东西 - (01) 了解Chat-GPT</title>
      <link>https://blog.meowsay.com/posts/devapp-with-ai-01-gpt4-and-chatgpt/</link>
      <pubDate>Tue, 12 Dec 2023 11:59:15 +0800</pubDate>
      
      <guid>https://blog.meowsay.com/posts/devapp-with-ai-01-gpt4-and-chatgpt/</guid>
      <description>OpenAI 通过 GPT 模型创造了出了 Chat-GPT，使人与计算机的交流，可以像人与人之间对话一样简单。GPT-4 和 其他的 GPT 模型都是大语言模型（LLMs），通过海量的数据进行训练，从而达到了能够精确识别与生成人类书写的文本。
这些 AI 应用的出现，不只是一个语音助手那么简单。通过 OpenAI 的模型，开发者可以通过超强的自然语言处理的能力，来创造曾经只存在科幻小说里的东西。通过现在的 AI 模型，可以做出更优秀的智能助理，智能服务系统。在教育行业，可以完全针对每一人的学习风格，实施对应的教学方案。GPT-4 和 ChatGPT 完全开创了一个新的领域。
但什么是 GPT-4 和 Chat-GPT 呢？本文旨在深入探讨这些人工智能模型的基础、起源和主要特点。了解了这些模型的基础知识，就可以很轻松的创造出下一代由 LLM 驱动的应用。
作为 LLM，GPT-4 和 ChatGPT 是 NLP 领域的最新模型类型，而 NLP 本身就是机器学习（ML）和人工智能的一个子领域。在深入研究 GPT-4 和 ChatGPT 之前，有必要先了解一下 NLP 及其相关领域。
人工智能有不同的定义，但其中一个定义（或多或少是共识）认为，人工智能是指开发能够执行通常需要人类智能才能完成的任务的计算机系统。根据这一定义，许多算法都属于人工智能的范畴。例如，考虑一下 GPS 应用中的交通预测任务或策略游戏中使用的基于规则的系统。在这些例子中，从用户的角度来看，机器似乎需要智能才能完成这些任务。
ML 是人工智能的一个子集。在 ML 中，我们并不试图直接实现人工智能系统使用的决策规则。相反，我们试图开发一种算法，让系统从实例中自我学习。自 20 世纪 50 年代开始研究 ML 以来，已经有很多 ML 算法被提出。
其中，深度学习算法的应用比较广泛。深度学习是 ML 的一个分支，主要研究受大脑结构启发的算法。这些算法被称为人工神经网络。它们可以处理大量数据，在图像和语音识别以及 NLP 等任务中表现出色。
GPT-4 和 ChatGPT 基于一种特殊的深度学习算法，称为 Transformer。Transformer 就像阅读机器。它们会关注句子或文本块的不同部分，以理解其上下文并做出连贯的反应。它们还能理解句子中单词的顺序及其上下文。这使它们在执行语言翻译、问题解答和文本生成等任务时非常有效。
NLP 是人工智能的一个子领域，侧重于使计算机能够处理、解释和生成人类自然语言。现代 NLP 解决方案基于 ML 算法。NLP 的目标是让计算机能够处理自然语言文本。这一目标涵盖了广泛的任务：</description>
    </item>
    
    <item>
      <title>关于 ChatGPT、GPT、GPT-3、OpenAI</title>
      <link>https://blog.meowsay.com/posts/about-chatgpt/</link>
      <pubDate>Wed, 29 Mar 2023 20:45:19 +0800</pubDate>
      
      <guid>https://blog.meowsay.com/posts/about-chatgpt/</guid>
      <description>2015年12月，一群聪明的人为了一个共同的目标走到了一起：以有利于整个人类的方式促进和发展友好的人工智能。 萨姆-奥特曼、伊隆-马斯克、格雷格-布罗克曼、里德-霍夫曼、杰西卡-利文斯顿、彼得-泰尔、亚马逊网络服务（AWS）、Infosys和YC Research宣布成立OpenAI，并向该企业认捐了超过10亿美元。该组织表示，它将通过向公众开放其专利和研究，与其他机构和研究人员进行 &amp;ldquo;自由合作&amp;rdquo;。
OpenAI的总部设在旧金山Mission区的Pioneer大厦。2016年4月，OpenAI发布了其强化学习研究平台 &amp;ldquo;OpenAI Gym &amp;ldquo;的公开测试版。2016年12月，OpenAI发布了 &amp;ldquo;Universe6&amp;rdquo;，这是一个软件平台，用于衡量和训练人工智能的通用智能，跨越世界上的游戏、网站和其他应用程序的供应。
2018年，埃隆-马斯克辞去了他的董事会席位，理由是与特斯拉自动驾驶汽车的人工智能开发存在 &amp;ldquo;潜在的未来利益冲突&amp;rdquo;，但他仍然是一个捐赠者。2019年，OpenAI从非营利性过渡到上限营利性，利润上限设定为任何投资的100倍。该公司向员工分配股权，并与微软合作，后者宣布向该公司投资10亿美元的一揽子计划。随后，OpenAI宣布打算对其技术进行商业化授权。
2020年，OpenAI宣布了GPT-3，这是一个根据互联网上的数万亿词汇训练的语言模型。它还宣布，一个相关的API，简单地命名为 &amp;ldquo;API&amp;rdquo;，将构成其第一个商业产品的核心。GPT-3的目标是自然语言回答问题，但它也可以在语言之间进行翻译，并连贯地生成即兴文本。2021年，OpenAI推出了DALL-E，这是一个深度学习模型，可以从自然语言描述中生成数字图像。 快进到2022年12月，OpenAI在推出ChatGPT的免费预览版后收到了广泛的媒体报道。据OpenAI称，该预览版在前五天内收到了超过一百万的注册用户。根据路透社在2022年12月援引的匿名消息，OpenAI预计2023年的收入为2亿美元，2024年为10亿美元。截至2023年1月，它正在进行融资谈判，该公司的价值将达到290亿美元。 这就是OpenAI的故事，它是一个人工智能研究实验室，由营利性公司OpenAI LP及其母公司、非营利性公司OpenAI Inc.组成。
在该公司发布流行的ChatGPT之前，大多数人都不知道OpenAI。 ChatGPT的主要目的是模仿人类行为，与人进行自然对话。然而，这个聊天机器人能够根据它与不同用户的对话来学习和教导自己。这个人工智能具有对话能力，可以编写教程和代码，谱写音乐，并执行其他任务。ChatGPT的用例相当多样化，可以说是无穷无尽；用户已经证明了这一点。有些用例是创造性的（如写一首说唱歌曲），有些是恶意的（如生成恶意代码或命令），还有一些是面向商业的（如搜索引擎优化、内容营销、电子邮件营销、冷处理电子邮件和商业生产力）。 ChatGPT只是代表生成性预训练转化器，是建立在OpenAI的GPT-3系列大型语言模型之上的。聊天机器人是用监督和强化学习技术进行微调的。
GPT-3是ChatGPT的基础。ChatGPT只是一个利用GPT-3的项目，并增加了一个网络界面、内存和更多的用户友好功能。读完本指南后，你将能够建立自己的聊天机器人，可能比ChatGPT更好，因为你可以根据自己的具体需要进行定制。
其他使用GPT-3的项目有：
GitHub Copilot（使用OpenAI Codex模型，是GPT-3的后裔，为生成代码进行了微调） Copy.ai7和Jasper.ai8（用于营销目的的内容生成） 德雷塞尔大学（检测阿尔茨海默病的早期症状） Algolia（增强其搜索引擎能力） 你肯定听说过GPT-4。GPT-4是GPT-3的继任者，也是由OpenAI创建的一个未发布的神经网络。 你可能已经看到了比较两个版本的GPT的图表，显示了GPT-3（1750亿）和GPT-4（100万亿）的参数数量。
当被问及这幅病毒性插图时，奥特曼称其为 &amp;ldquo;完全是胡说八道&amp;rdquo;。&amp;ldquo;GPT-4的谣言是一个荒谬的事情。我不知道这一切从何而来。人们在乞求失望，他们会失望的。炒作就像&amp;hellip; 我们没有一个真正的AGI，这也算是对我们的期望吧&amp;rdquo;。</description>
    </item>
    
    <item>
      <title>搭建自己的AI图片生成器</title>
      <link>https://blog.meowsay.com/posts/create-your-own-ai-image-generator/</link>
      <pubDate>Mon, 27 Mar 2023 14:41:51 +0800</pubDate>
      
      <guid>https://blog.meowsay.com/posts/create-your-own-ai-image-generator/</guid>
      <description>最近一段时间，使用 Stable Diffusion 等工具生成图片的资讯充斥着整个互联网，但是很多在线的 AI 图片生成工具，要么根本访问不了（需要科学上网），要么就是需要付费，而且还巨慢。作为一个常年混迹于互联网的技术流玩家，我觉得有必要在自己本机搭一下无限制的 AI 图片生成工具。
本地搭建这东西我觉得还是很有用的，对于我来说，写博客，公众号的一些配图，完全可以用这东西生成。还有最重要的，我是想用在独立游戏开发中，让我做的那些垃圾文字游戏，可以多一点图片，增加哪怕一点点美感和吸引力。
我们用的工具是 Stable Diffusion。由于我的机器是 Mac M1 芯片的，所以教程也就是在此配置上去搭建，其他平台类似。
1. 确认 Python 环境 首先确保自己机器上的 Python3 版本是 3.10 以上，使用命令 python3 --version 可以查看。如果还没有安装 Python3 则使用命令 brew install python3 来安装。如果版本比 3.10 低，则使用 brew upgrade python3 来升级到最新版本
2. 下载 Stable Diffusion 的 Web 工程 使用命令 git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui 来克隆 Stable Diffusion 的 web 工程，这个工程可以让我们在浏览器中使用 Stable Diffusion。 注意，这个过程可能会异常的慢，甚至可以失败，如果失败了，那就重新执行命令，或者采取一些科学的网络方式对其进行下速，反正相办法下载下来就行。
3. 下载模型文件，模型文件，可以理解为官方或其他人已经训练好的一些参数集合，有了这个，生成工具才知道怎么去生成一张图片。 先下载官方的基础 Model，这里使用的是 1.5 版本的，2.0 版本的不在此博客的讨论范围内，因为我也没用过。
点击这里下载 v1-5-pruned.ckpt
下载完成后，将这个文件放入 stable-diffusion-webui/models/Stable-diffusion 目录下</description>
    </item>
    
    <item>
      <title>使用 OpenAI 的最佳实践</title>
      <link>https://blog.meowsay.com/posts/best-practice-openai-prompt/</link>
      <pubDate>Thu, 23 Mar 2023 13:54:08 +0800</pubDate>
      
      <guid>https://blog.meowsay.com/posts/best-practice-openai-prompt/</guid>
      <description>如何向GPT-3和Codex提供清晰有效的指令。
Prompt 是怎样工作的 由于指令跟随模型的训练方式或它们所接受的数据，有特定的提示格式可以很好地配合当前任务并可靠地发挥作用。以下是我们发现可靠有效的一些提示格式，但请随意尝试不同格式，以找到最适合您任务的格式。
经验法则和示例 注意：&amp;quot;{text input here}&amp;ldquo;是实际文本/上下文的占位符
1. 使用最新模型 为了获得最佳结果，我们通常建议使用最新、功能最强大的模型。截至2022年11月，生成文本的最佳选项是“text-davinci-003”模型，生成代码的最佳选项是“code-davinci-002”模型。
2. 在提示的开头放置说明，并使用###或&amp;rdquo;&amp;ldquo;&amp;ldquo;分隔指令和上下文 低效方式
Summarize the text below as a bullet point list of the most important points. {text input here} 高效方式
Summarize the text below as a bullet point list of the most important points. Text: &amp;#34;&amp;#34;&amp;#34; {text input here} &amp;#34;&amp;#34;&amp;#34; 3. 请尽可能具体、描述性和详细地说明所需的上下文、结果、长度、格式、风格等。 请具体说明上下文、结果、长度、格式和风格等。
低效方式
Write a poem about OpenAI. 高效方式
Write a short inspiring poem about OpenAI, focusing on the recent DALL-E product launch (DALL-E is a text to image ML model) in the style of a {famous poet} 4.</description>
    </item>
    
  </channel>
</rss>
